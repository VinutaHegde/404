{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Discriminator",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSeY-MUQo2Ha",
        "colab_type": "code",
        "outputId": "ec88222f-f0e0-4bd8-d15e-c3112c8de7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "np.random.seed(10)\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "\n",
        "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
        "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
        "category_counts = 2\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKzV1EqKsC80",
        "colab_type": "text"
      },
      "source": [
        "# **Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fllZkVjXKV",
        "colab_type": "code",
        "outputId": "7d04a232-2dfd-40d7-ad26-a4f8cd720cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
        "dense = layers.Dense(256, activation='relu')(embedding)\n",
        "pred = layers.Dense(category_counts, activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "last_hidden_weight_w=model.layers[3].get_weights()[0] #weights\n",
        "last_hidden_weight_b=model.layers[3].get_weights()[1] #Biases\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 131,842\n",
            "Trainable params: 131,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXfVkKFssJPJ",
        "colab_type": "text"
      },
      "source": [
        "# **Preparing the Input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ube1DvYEJ3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "train_text=np.array([\"This is my fist sentence\", \"this is my second Sentence\", \"I 'm so happy !\", \"I 'm very sleepy\"])\n",
        "train_labels=np.array([\"0\",\"0\",\"1\",\"1\"])\n",
        "encoder = MultiLabelBinarizer()\n",
        "encoder.fit_transform(train_labels)\n",
        "train_label = encoder.transform(train_labels)\n",
        "\n",
        "test_text=np.array([\"This is my try\", \"this is my second\", \"I 'm so lazy !\", \"I 'm very very\"])\n",
        "test_labels=np.array([\"0\",\"0\",\"1\",\"1\"])\n",
        "encoder = MultiLabelBinarizer()\n",
        "encoder.fit_transform(test_labels)\n",
        "test_label = encoder.transform(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqcRy_JWXe0u",
        "colab_type": "text"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_stfC_7VFhS8",
        "colab_type": "code",
        "outputId": "a8adc39a-d00d-45e0-b64a-fc6392c58d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  history = model.fit(train_text, \n",
        "            train_label,\n",
        "            validation_data=(test_text, test_label),\n",
        "            epochs=10,\n",
        "            batch_size=32)\n",
        "  model.save_weights('./model.h5')\n",
        "  print(last_hidden_weight_w)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4 samples, validate on 4 samples\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 2s 478ms/step - loss: 0.7151 - acc: 0.0000e+00 - val_loss: 0.6890 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6370 - acc: 1.0000 - val_loss: 0.6689 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5738 - acc: 1.0000 - val_loss: 0.6500 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5197 - acc: 1.0000 - val_loss: 0.6313 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4704 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4249 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 1.0000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3827 - acc: 1.0000 - val_loss: 0.5754 - val_acc: 1.0000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3430 - acc: 1.0000 - val_loss: 0.5581 - val_acc: 1.0000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3059 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 1.0000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2716 - acc: 1.0000 - val_loss: 0.5264 - val_acc: 1.0000\n",
            "[[ 0.0278791   0.00779122]\n",
            " [ 0.14899296 -0.00390171]\n",
            " [ 0.11884362  0.09706031]\n",
            " [ 0.13711494 -0.1245061 ]\n",
            " [-0.14385459 -0.14261161]\n",
            " [ 0.12220424 -0.04639435]\n",
            " [ 0.12684527  0.04081987]\n",
            " [ 0.1450387   0.0785443 ]\n",
            " [ 0.1379363  -0.08597329]\n",
            " [-0.06217295 -0.15108863]\n",
            " [-0.07855064 -0.14498825]\n",
            " [ 0.11723781 -0.11652759]\n",
            " [ 0.06488326  0.14507776]\n",
            " [ 0.12806022  0.02404842]\n",
            " [ 0.08135933  0.07148902]\n",
            " [ 0.02435048  0.01652883]\n",
            " [-0.13984764  0.08012739]\n",
            " [-0.05318818  0.07390042]\n",
            " [-0.0228111  -0.02489601]\n",
            " [-0.14994352 -0.09707874]\n",
            " [ 0.13701645  0.00943856]\n",
            " [-0.04623117 -0.07092538]\n",
            " [-0.10755856  0.11597702]\n",
            " [ 0.02682802 -0.09743185]\n",
            " [ 0.02788872  0.02012792]\n",
            " [-0.08955817 -0.07326447]\n",
            " [-0.02849473  0.14822948]\n",
            " [ 0.09319857 -0.15036437]\n",
            " [-0.13559315 -0.06210376]\n",
            " [-0.04907978 -0.050529  ]\n",
            " [ 0.00239293 -0.10742597]\n",
            " [-0.01209196  0.0754602 ]\n",
            " [-0.01741736  0.04370062]\n",
            " [ 0.09572788  0.0015288 ]\n",
            " [-0.1442556   0.12196729]\n",
            " [ 0.14123324 -0.1366779 ]\n",
            " [ 0.12693226 -0.05427068]\n",
            " [-0.0367832  -0.15183035]\n",
            " [ 0.03557101 -0.12570797]\n",
            " [-0.02682035 -0.07249971]\n",
            " [-0.1044036  -0.09639221]\n",
            " [-0.05177289 -0.06974614]\n",
            " [-0.14757818  0.032142  ]\n",
            " [-0.05817425  0.13231346]\n",
            " [ 0.07666741 -0.07985583]\n",
            " [ 0.0009142  -0.12947157]\n",
            " [-0.09274677  0.14480162]\n",
            " [ 0.14347392 -0.15037394]\n",
            " [ 0.08610426 -0.14011768]\n",
            " [ 0.09802037 -0.12491782]\n",
            " [ 0.14104626 -0.00026883]\n",
            " [ 0.08286275 -0.10294515]\n",
            " [ 0.02565826  0.12374747]\n",
            " [-0.04351155 -0.14889494]\n",
            " [-0.01844259 -0.14456017]\n",
            " [ 0.0989399   0.06688319]\n",
            " [ 0.1352551   0.04711708]\n",
            " [-0.05475672  0.06728044]\n",
            " [-0.0215255  -0.13458373]\n",
            " [ 0.07740752 -0.08303302]\n",
            " [-0.12872288 -0.07541922]\n",
            " [-0.12935464  0.07836576]\n",
            " [ 0.11238945  0.13697803]\n",
            " [ 0.0324509  -0.11448014]\n",
            " [ 0.13348293 -0.11639801]\n",
            " [-0.09637906 -0.04673673]\n",
            " [-0.10241657  0.02411841]\n",
            " [-0.13763188 -0.10651893]\n",
            " [-0.09154131  0.03599146]\n",
            " [-0.0136569  -0.14258528]\n",
            " [-0.08740705  0.13701761]\n",
            " [ 0.15089917  0.07232501]\n",
            " [-0.08563505  0.1104252 ]\n",
            " [ 0.01054312  0.10430375]\n",
            " [ 0.06494725 -0.07683241]\n",
            " [ 0.00621316 -0.1100997 ]\n",
            " [-0.02276456 -0.12061654]\n",
            " [ 0.07122494  0.09954354]\n",
            " [ 0.1058363   0.00901546]\n",
            " [-0.03314273 -0.02796317]\n",
            " [ 0.0274848   0.12806538]\n",
            " [ 0.09735692 -0.11257753]\n",
            " [-0.05523055  0.09341988]\n",
            " [ 0.01511782 -0.03153507]\n",
            " [ 0.13176638 -0.13988352]\n",
            " [ 0.0150269   0.06973061]\n",
            " [ 0.04110244 -0.00286563]\n",
            " [-0.00054276 -0.14988577]\n",
            " [-0.00016677  0.04471891]\n",
            " [ 0.03507577 -0.05931586]\n",
            " [-0.09589596  0.09653129]\n",
            " [-0.13620044 -0.1281235 ]\n",
            " [ 0.12734348 -0.11188029]\n",
            " [-0.11201339  0.02350824]\n",
            " [-0.12375464  0.14610907]\n",
            " [ 0.0234818  -0.12734883]\n",
            " [ 0.04934789  0.07675682]\n",
            " [-0.13995636  0.15128464]\n",
            " [-0.14192389  0.05529568]\n",
            " [ 0.12219709 -0.0785514 ]\n",
            " [-0.0464106   0.10672402]\n",
            " [-0.04400345  0.02518921]\n",
            " [-0.11642174 -0.14406885]\n",
            " [ 0.13946655 -0.0504493 ]\n",
            " [ 0.03726175 -0.11053698]\n",
            " [ 0.14879826  0.12144381]\n",
            " [ 0.00637488  0.07947588]\n",
            " [-0.0621187   0.09456506]\n",
            " [ 0.03242141  0.06153174]\n",
            " [ 0.13502342  0.08080944]\n",
            " [ 0.14036134 -0.04722648]\n",
            " [-0.00511274  0.1409285 ]\n",
            " [ 0.15040481 -0.05220025]\n",
            " [-0.07648903 -0.08291245]\n",
            " [ 0.13017714  0.10072747]\n",
            " [-0.08898839 -0.13383564]\n",
            " [-0.12352242 -0.03244788]\n",
            " [-0.00962558  0.04070555]\n",
            " [-0.02180779  0.03911966]\n",
            " [-0.12589881  0.00342363]\n",
            " [ 0.10504943  0.00598152]\n",
            " [-0.12380441  0.09339003]\n",
            " [-0.06798708  0.15172446]\n",
            " [ 0.09794483 -0.02950935]\n",
            " [-0.1470028  -0.0981483 ]\n",
            " [-0.12525377  0.0741041 ]\n",
            " [ 0.10226473  0.0749871 ]\n",
            " [ 0.00494632  0.12494478]\n",
            " [ 0.02678126 -0.07154021]\n",
            " [-0.06648921  0.09722193]\n",
            " [ 0.03724404  0.01022273]\n",
            " [ 0.10920647 -0.03815791]\n",
            " [-0.03243425  0.01646891]\n",
            " [-0.06479549  0.12843168]\n",
            " [ 0.00667851 -0.13579491]\n",
            " [ 0.11287755 -0.11258171]\n",
            " [-0.0915028   0.13564336]\n",
            " [ 0.00182386  0.10861486]\n",
            " [-0.01264359  0.02611336]\n",
            " [ 0.03241232  0.01030192]\n",
            " [-0.08887168  0.12209308]\n",
            " [ 0.1321463  -0.01531565]\n",
            " [-0.09371293 -0.07816738]\n",
            " [ 0.13047493 -0.04597738]\n",
            " [ 0.02765721 -0.10799425]\n",
            " [-0.08566992 -0.04255434]\n",
            " [-0.04756458  0.03138411]\n",
            " [-0.02496159 -0.11533001]\n",
            " [ 0.1224789  -0.07229225]\n",
            " [-0.04586424  0.09759116]\n",
            " [ 0.01683417  0.11850429]\n",
            " [-0.13628942  0.00621876]\n",
            " [-0.11113766  0.02397931]\n",
            " [-0.06732927  0.00904992]\n",
            " [ 0.0318287   0.06728776]\n",
            " [ 0.13884148  0.14948153]\n",
            " [-0.04812144 -0.13032138]\n",
            " [-0.03714598  0.03693546]\n",
            " [ 0.0863492   0.12556213]\n",
            " [ 0.03729004 -0.01805486]\n",
            " [-0.07886699  0.03846158]\n",
            " [-0.01077797  0.09697999]\n",
            " [ 0.03438649 -0.03187862]\n",
            " [-0.11769441  0.11022577]\n",
            " [ 0.1361709   0.15175366]\n",
            " [-0.11860089  0.02845256]\n",
            " [ 0.12044424  0.14602455]\n",
            " [-0.10175525 -0.06294844]\n",
            " [-0.04611184 -0.13168003]\n",
            " [-0.14282209 -0.14667176]\n",
            " [-0.12298839  0.02283931]\n",
            " [-0.03913061 -0.07757724]\n",
            " [ 0.12632093  0.03813261]\n",
            " [-0.08592021 -0.12593663]\n",
            " [-0.13731661 -0.13646597]\n",
            " [-0.15138975 -0.13539183]\n",
            " [-0.07804122  0.01209189]\n",
            " [ 0.11859134  0.03692317]\n",
            " [ 0.02147546 -0.03065886]\n",
            " [-0.04274693 -0.06822456]\n",
            " [ 0.09916091  0.08880074]\n",
            " [ 0.09532768 -0.03433725]\n",
            " [ 0.01883198  0.04769747]\n",
            " [ 0.03979921  0.09626536]\n",
            " [ 0.13012418 -0.08638262]\n",
            " [ 0.13330066 -0.13538125]\n",
            " [ 0.07464159  0.0111866 ]\n",
            " [-0.01273489  0.13964143]\n",
            " [ 0.0479362  -0.1520262 ]\n",
            " [-0.08467133  0.01516466]\n",
            " [ 0.03425436  0.15069026]\n",
            " [ 0.05661526 -0.10124419]\n",
            " [ 0.03221469 -0.09488876]\n",
            " [-0.02504587  0.1472955 ]\n",
            " [ 0.10983014  0.10419765]\n",
            " [-0.11913231 -0.09469806]\n",
            " [ 0.14625692 -0.13933262]\n",
            " [ 0.03106695  0.06373717]\n",
            " [-0.04626974  0.07715352]\n",
            " [ 0.14901048  0.05732949]\n",
            " [ 0.05790897  0.10175538]\n",
            " [-0.06374945  0.01222274]\n",
            " [-0.14814778  0.08752267]\n",
            " [-0.09477648  0.12095374]\n",
            " [ 0.0503937   0.10566446]\n",
            " [ 0.12721956  0.04976307]\n",
            " [-0.03342088  0.04388332]\n",
            " [ 0.0948516   0.06939684]\n",
            " [ 0.14129844  0.08245942]\n",
            " [-0.11186163 -0.01267922]\n",
            " [ 0.1479733  -0.02295442]\n",
            " [-0.12444843 -0.07722351]\n",
            " [-0.11786489  0.02087599]\n",
            " [-0.06928515 -0.01683867]\n",
            " [ 0.11273235 -0.0636098 ]\n",
            " [ 0.14413524 -0.07500626]\n",
            " [-0.14549462  0.0611075 ]\n",
            " [ 0.04905826  0.07173087]\n",
            " [-0.04886051 -0.09769672]\n",
            " [ 0.00189966 -0.03396159]\n",
            " [ 0.04597299 -0.09222819]\n",
            " [-0.08409196 -0.1433306 ]\n",
            " [ 0.00994179 -0.07662822]\n",
            " [-0.11060861 -0.06014208]\n",
            " [-0.13670401 -0.00564134]\n",
            " [ 0.00525278 -0.03221857]\n",
            " [ 0.1495241  -0.04782273]\n",
            " [-0.08449426  0.07484072]\n",
            " [ 0.12092656  0.01625457]\n",
            " [-0.08002941 -0.06724471]\n",
            " [-0.06282275  0.06071821]\n",
            " [-0.15097442 -0.14089319]\n",
            " [-0.08006631  0.09144935]\n",
            " [ 0.0858952   0.01118372]\n",
            " [ 0.02257299 -0.13954797]\n",
            " [-0.10905562  0.06812996]\n",
            " [-0.12711962 -0.10129596]\n",
            " [-0.15119345  0.01754181]\n",
            " [-0.08900984 -0.05060444]\n",
            " [ 0.10492823  0.00605813]\n",
            " [ 0.01049136  0.00369039]\n",
            " [-0.11438128  0.0433042 ]\n",
            " [ 0.04829066  0.07703467]\n",
            " [-0.11461237  0.10339689]\n",
            " [-0.09765448  0.09648271]\n",
            " [ 0.11835125 -0.10000615]\n",
            " [-0.0093834  -0.07172931]\n",
            " [-0.01439059  0.0211641 ]\n",
            " [ 0.0412578   0.06687531]\n",
            " [ 0.11042538 -0.04081154]\n",
            " [ 0.00618003 -0.13316916]\n",
            " [ 0.13368705 -0.01593222]\n",
            " [ 0.15180671  0.09450462]\n",
            " [-0.08083151 -0.11950383]\n",
            " [-0.07142644 -0.06273407]\n",
            " [ 0.00398172 -0.10167638]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW1CiBhnXnxa",
        "colab_type": "code",
        "outputId": "62617488-9519-4fbc-d725-c4e8da5165a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!ls -alh | grep model.h5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 530K Nov 11 09:03 model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQux6qLdXabG",
        "colab_type": "text"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSDxetlfUEiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_text = [\"In what year did the titanic sink ?\", \"What is the highest peak in California ?\", \"Who invented the light bulb ?\"]\n",
        "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  predicts = model.predict(new_text, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaR0d5VPU23Z",
        "colab_type": "code",
        "outputId": "ba49b721-7494-45ad-b227-9ba8c6e66533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "predicts"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5625144 , 0.43748555],\n",
              "       [0.48502126, 0.5149787 ],\n",
              "       [0.5769549 , 0.42304507]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyDGVtigW57f",
        "colab_type": "code",
        "outputId": "227ff465-2f5a-4593-fc89-7192ca3d1944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "categories = [\"0\",\"1\"]\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "predict_labels = [categories[logit] for logit in predict_logits]\n",
        "predict_labels"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1', '0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}