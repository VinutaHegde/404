{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def someFunction(self,list_IDs_temp):\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, image_embedding, captions, batch_size=32,num_caption = 92, caption_dim =300, image_dim=(2048), n_channels=1, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.image_dim = image_dim\n",
    "        self.caption_dim = caption_dim\n",
    "        self.num_caption = num_caption\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "#         self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.image_embedding = image_embedding\n",
    "        self.captions = captions\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        X = np.empty((self.batch_size, self.image_dim))\n",
    "        Y = np.empty((self.batch_size, self.num_caption, self.caption_dim ))\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = self.image_embedding[ID]\n",
    "            Y[i] = self.captions[ID]\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import csv\n",
    "\n",
    "SEED = 10\n",
    "IMAGE_EMBEDDING_DIR = '/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/'\n",
    "NUM_IMAGE_EMBEDDING_CHUNKS = 2\n",
    "GLOVE_EMBEDDING_FILE_NAME = 'glove.6B.300d.txt'\n",
    "CAPTION_FILE_NAME = '/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/image_to_caption.csv'\n",
    "MAX_SEQUENCE_LENGTH = 92\n",
    "WORD_EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class text_encoder:\n",
    "    def get_embedding_matrix(self,filename, WORD_EMBEDDING_DIM):\n",
    "        embeddings_index = {}\n",
    "        word_to_index = {}\n",
    "\n",
    "        with open(filename) as f:\n",
    "            for index, line in enumerate(f):\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "                word_to_index[word] = index\n",
    "\n",
    "          # Vocabulary\n",
    "        vocabulary = embeddings_index.keys()\n",
    "        embedding_matrix = np.zeros((len(vocabulary) + 1, WORD_EMBEDDING_DIM))\n",
    "\n",
    "        for word, i in word_to_index.items():\n",
    "            embedding_vector = embeddings_index[word]\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "\n",
    "        return embedding_matrix, vocabulary, word_to_index\n",
    "    \n",
    "    def load_embeddings(self):\n",
    "        embedding_matrix, vocabulary, word_to_index = self.get_embedding_matrix(GLOVE_EMBEDDING_FILE_NAME, WORD_EMBEDDING_DIM)      \n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.vocabulary = vocabulary\n",
    "        self.word_to_index = word_to_index\n",
    "        \n",
    "    def get_sentence_embedding(self,sentence):\n",
    "        words = sentence.split()    \n",
    "        sentence_embedding =  np.zeros(shape=(MAX_SEQUENCE_LENGTH,WORD_EMBEDDING_DIM))\n",
    "        mask =  np.zeros(MAX_SEQUENCE_LENGTH)\n",
    "        i=0;\n",
    "        for w in words:\n",
    "            mask[i] = 1\n",
    "            index = self.word_to_index.get(w,-1)\n",
    "            if(index != -1):\n",
    "                sentence_embedding[i] = self.embedding_matrix[index]\n",
    "            else:\n",
    "                sentence_embedding[i] = np.zeros(WORD_EMBEDDING_DIM)\n",
    "            i+=1       \n",
    "        return  sentence_embedding, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge(dict1, dict2): \n",
    "    res = {**dict1, **dict2} \n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbedding():\n",
    "    image_embedding = {}\n",
    "    for i in range (NUM_IMAGE_EMBEDDING_CHUNKS):\n",
    "        file_name = IMAGE_EMBEDDING_DIR + 'group_'+str(i+1)+'.json'\n",
    "        with open(file_name) as json_file:\n",
    "            print(file_name)\n",
    "            json_data = json.load(json_file)\n",
    "            json_data = json.loads(json_data)\n",
    "            image_embedding = Merge(image_embedding, json_data) \n",
    "        return image_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCaptions(id_list,text_ebmd_encoder):\n",
    "    caption_dict = {}\n",
    "    with open(CAPTION_FILE_NAME) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if row[1] in id_list:\n",
    "#                  print(row[1] +\"  \"+ row[2])\n",
    "                 embd, mask = text_ebmd_encoder.get_sentence_embedding(row[2])\n",
    "                 caption_dict[row[1]] = embd\n",
    "#                  print( caption_dict[row[1]])\n",
    "\n",
    "    return caption_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPartitions(image_list_file_name):\n",
    "    with open(image_list_file_name) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "#         json_data = json.loads(data)\n",
    "        print(len(json_data))\n",
    "        return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81155\n",
      "73040\n",
      "8115\n",
      "/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/group_1.json\n",
      "(64, 2048)\n",
      "(64, 92, 300)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "random.seed(SEED)\n",
    "\n",
    "params = {'num_caption': 92,\n",
    "          'caption_dim' :300,\n",
    "          'image_dim' : 2048,\n",
    "          'batch_size': 64,\n",
    "          'shuffle': True}\n",
    "\n",
    "ids = getPartitions('/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/imgaes_with_captions.txt')\n",
    "random.shuffle(ids)\n",
    "\n",
    "id_len = len(ids)\n",
    "partition = {}\n",
    "\n",
    "partition['train'] = ids[:int((id_len+1)*.90)] #Remaining 90% to training set\n",
    "partition['validation'] = ids[int(id_len*.90+1):] #Splits 10% data to test set\n",
    "\n",
    "print(len(partition['train']))\n",
    "print(len(partition['validation']))\n",
    "\n",
    "image_embedding = getImageEmbedding()\n",
    "text_ebmd_encoder = text_encoder()\n",
    "text_ebmd_encoder.load_embeddings()\n",
    "captions = getCaptions(image_embedding.keys(),text_ebmd_encoder);\n",
    "\n",
    "\n",
    "training_generator = DataGenerator(partition['train'], image_embedding, captions , **params)\n",
    "validation_generator = DataGenerator(partition['validation'], image_embedding, captions, **params)\n",
    "\n",
    "id_filtered = list(image_embedding.keys())\n",
    "x =id_filtered[:64]\n",
    "train_X, train_Y = training_generator.someFunction(x)\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "404",
   "language": "python",
   "name": "404"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
