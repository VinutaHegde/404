{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_TA_SEGGESTION_No Image Embed Layer _ 3inputs_Need to use the inference notebook_seqlen20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lX-B3q67XANg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "389da1bc-be09-4c62-fdd3-f238cca2d521"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import string\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "from pickle import dump, load\n",
        "from time import time\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization, GRU, Masking, Lambda, Concatenate\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.merge import add\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras import Input, layers\n",
        "from keras import optimizers\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "# from numpy import argmax\n",
        "# from pickle import load\n",
        "# from keras.preprocessing.text import Tokenizer\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "# # from nltk.translate.bleu_score import corpus_bleu\n",
        "import json\n",
        "# import random\n",
        "import csv\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#Wesam\n",
        "# SEED = 10\n",
        "#IMAGE_EMBEDDING_VAL_DIR = '/content/drive/My Drive/Colab_Notebooks/DL_data/validation/'\n",
        "# IMAGE_EMBEDDING_DIR = '/content/drive/My Drive/Colab_Notebooks/DL_data/one_sample_cnn/'\n",
        "# filepath = '/content/drive/My Drive/Colab_Notebooks/DL_data/model-ep{epoch:03d}-loss{loss:.3f}.h5'\n",
        "#CAPTION_FILE_NAME = '/content/drive/My Drive/Colab_Notebooks/DL_data/image_to_caption.csv'\n",
        "\n",
        "\n",
        "\n",
        "#on my Colab\n",
        "ALL_CAPTIONS_FILE = '/content/drive/My Drive/Colab_Notebooks/DL_data/all_captions.txt'\n",
        "COMPLETE_STORIES_FILE = '/content/drive/My Drive/Colab_Notebooks/DL_data/complete_stories_all_splits.json'\n",
        "IMAGE_EMBEDDING_DIR = '/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/'\n",
        "GLOVE_EMBEDDING_FILE_NAME = '/content/drive/My Drive/Colab_Notebooks/DL_data/glove.6B.300d.txt'\n",
        "\n",
        "\n",
        "# #For my GCP:\n",
        "# ALL_CAPTIONS_FILE = 'all_captions.txt'\n",
        "# COMPLETE_STORIES_FILE = 'complete_stories_all_splits.json'\n",
        "# IMAGE_EMBEDDING_DIR = 'CNNFeatureVectors/'\n",
        "# GLOVE_EMBEDDING_FILE_NAME = 'glove.6B.300d.txt'\n",
        "\n",
        "\n",
        "#Vinuta\n",
        "SEED = 10\n",
        "IMAGE_EMBEDDING_DIM = 2048\n",
        "#IMAGE_EMBEDDING_DIR = '/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/'\n",
        "NUM_IMAGE_EMBEDDING_CHUNKS = 10\n",
        "#GLOVE_EMBEDDING_FILE_NAME = 'glove.6B.300d.txt'\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "WORD_EMBEDDING_DIM = 300\n",
        "#CAPTION_FILE_NAME = '/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/image_to_caption.csv'\n",
        "SENTENCE_EMBEDDING_DIM = 512"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCvM68FbJ7h6",
        "colab_type": "code",
        "outputId": "8a7604e8-1232-4521-e380-26768a8642fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#commented for GCP\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iuq6CmUtYsEE"
      },
      "source": [
        "#PreProcess Captions / Stories\n",
        "\n",
        "Either call this function or simply load preprocessed from a file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqQ7qPFcRDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to check if story ids are repeated or unique\n",
        "# story_list = list()\n",
        "# for key in list(all_captions_dict.keys()):\n",
        "#   story_list += list(all_captions_dict[key].keys())\n",
        "# from collections import Counter\n",
        "# print(len(story_dict))\n",
        "# d =  Counter(story_dict)\n",
        "# res = [k for k, v in d.items() if v > 1]\n",
        "# print(len(res)) ## gave zero .. so story ids are -in fact- unique\n",
        "\n",
        "\n",
        "#image_embd =  getImageEmbedding(IMAGE_EMBEDDING_DIR)\n",
        "\n",
        "def get_existing_stories(image_embeddings):\n",
        "  #load all_captions file\n",
        "  with open(ALL_CAPTIONS_FILE) as json_file:\n",
        "    all_captions_dict = json.load(json_file)\n",
        "\n",
        "  #Create a story dict (no album ids (already checked that story ids are unique))\n",
        "  story_dict = {}\n",
        "  for key in list(all_captions_dict.keys()):\n",
        "    story_dict.update(all_captions_dict[key])\n",
        "\n",
        "\n",
        "  # Create a Story dict where all images are available in the image_embeddings\n",
        "  existing_stories = {}\n",
        "  c=0\n",
        "  for key in list(story_dict.keys()):\n",
        "    lists = story_dict[key]\n",
        "    images = [item[0] for item in lists]\n",
        "    #captions = ['startseq ' + item[1] + ' endseq' for item in lists]\n",
        "    captions = [item[1] for item in lists]\n",
        "    if all(img in list(image_embeddings.keys()) for img in images):\n",
        "      existing_stories[key] = [images,captions]\n",
        "      c+=1\n",
        "      \n",
        "  print(\"Number of Stories Found: \")\n",
        "  print(c)\n",
        "\n",
        "  # Saving the complete existing story dict in a file\n",
        "  with open(COMPLETE_STORIES_FILE, 'w') as fp:\n",
        "      json.dump(existing_stories, fp)\n",
        "  return existing_stories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiEKE0VJHSsU",
        "colab_type": "text"
      },
      "source": [
        "#Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "16o6JbtNXHVa",
        "colab": {}
      },
      "source": [
        " def vocab_fun(existing_stories_dict):\n",
        "  index_to_word = {}\n",
        "  word_to_index = {}\n",
        "  max_seq_len=0\n",
        "  all_words = {}\n",
        "  all_words['startseq'] = 1\n",
        "  all_words['endseq'] = 1\n",
        "  cap_list = list()\n",
        "  for story_id, lists in existing_stories_dict.items():\n",
        "    for cap in lists[1]:\n",
        "      if(len(cap.split())>max_seq_len):\n",
        "        max_seq_len = len(cap.split())\n",
        "      for word in cap.split():\n",
        "        all_words[word] = 1\n",
        "  all_vocab=[w for w in all_words]\n",
        "  index = 1\n",
        "  for word in all_vocab:\n",
        "      word_to_index[word] = index\n",
        "      index_to_word[index] = word\n",
        "      index += 1\n",
        "\n",
        "\n",
        "\n",
        "  #MAX_SEQUENCE_LENGTH = #max_seq_len + 1\n",
        "  return (all_vocab, word_to_index, index_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2-PgnES0nhe",
        "colab_type": "code",
        "outputId": "d7c15411-7f34-49cc-9532-06a592d914e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# #to deciede sentence length:\n",
        "\n",
        "# cap_lengths=[]\n",
        "# for key, lists in existing_stories.items():\n",
        "#     cap_list=lists[1]\n",
        "#     for x in cap_list:\n",
        "#       for c in x.split():\n",
        "#         cap_lengths.append(len(c))\n",
        "# print(np.mean(cap_lengths)+ 2 * np.std(cap_lengths))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.402385321992504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pl15hHkcYxYj"
      },
      "source": [
        "#Preprocess images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90V-9vXXYjgx",
        "colab": {}
      },
      "source": [
        "def Merge(dict1, dict2): \n",
        "    res = {**dict1, **dict2} \n",
        "    return res \n",
        "\n",
        "def getImageEmbedding(path):\n",
        "    image_embedding = {}\n",
        "    for i in range(NUM_IMAGE_EMBEDDING_CHUNKS):\n",
        "         file_name = path + 'cnn_group'+str(i+1)+'.json'\n",
        "         with open(file_name) as json_file:\n",
        "            print(file_name)\n",
        "            json_data = json.load(json_file)\n",
        "            json_data = json.loads(json_data)\n",
        "            image_embedding = Merge(image_embedding, json_data) \n",
        "    return image_embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuKPEQrk-FBz",
        "colab_type": "text"
      },
      "source": [
        "#Load Stories (captions with corresponding Image ids)\n",
        "##Dict items as follows (per story)\n",
        "[ [img_id1, img_id2, img_id3, img_id4, img_id5] , [cap1, cap2, cap3, cap4, cap5] ]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsfYfloT9dz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_existing_stories_from_file():\n",
        "  with open(COMPLETE_STORIES_FILE, 'r') as fp:\n",
        "      existing_stories = json.load(fp)\n",
        "  return existing_stories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6dJwBxEGaYNy"
      },
      "source": [
        "#Use Prev to get captions / stories and images and pre_process them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XMqm0aZXaYgo",
        "outputId": "ca03328f-d08d-4788-e22a-f4206b526062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#for training\n",
        "image_embd =  getImageEmbedding(IMAGE_EMBEDDING_DIR)\n",
        "print(len(image_embd))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group1.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group2.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group3.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group4.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group5.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group6.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group7.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group8.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group9.json\n",
            "/content/drive/My Drive/Colab_Notebooks/DL_data/CNNFeatureVectors/cnn_group10.json\n",
            "58197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9FZmz0inN6Z",
        "colab_type": "code",
        "outputId": "b36adb61-c0c5-4e91-a90a-018338298ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#get existing_stories (either load from file or using a function , preferably load from file) -- uncomment one of the following 2 lines\n",
        "existing_stories = get_existing_stories_from_file()\n",
        "#existing_stories = get_existing_stories(image_embd) #Number of Stories Found: 35565\n",
        "\n",
        "all_vocab, wordtoix, ixtoword=vocab_fun(existing_stories)\n",
        "print('Max Seq Len: %d' %MAX_SEQUENCE_LENGTH)\n",
        "vocab_size = len(all_vocab) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size) #26571"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Seq Len: 20\n",
            "Vocabulary Size: 26572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9U_jDKeohyJ",
        "colab_type": "code",
        "outputId": "114fa20b-8408-49f5-8467-98815978ba7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Sample Example from Esisting Stories\n",
        "print(existing_stories['2905'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['4562798695', '4563429868', '4562801065', '4563434166', '4563436748'], ['my trip to location was amazing .', 'i saw some colorful people .', 'i even made some knew friends .', 'i visited a beautiful pagoda .', 'then i saw a ordinary bicycle .']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8amlOYORaY6U"
      },
      "source": [
        "#Word Embedding Matrix\n",
        "###Using Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0TgQ6BKaZSA",
        "outputId": "52c349e0-1398-4414-c69f-a9649f8883cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#get matrix embedding for glove\n",
        "embeddings_index = {} # empty dictionary\n",
        "f = open(GLOVE_EMBEDDING_FILE_NAME, encoding=\"utf-8\")\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "\n",
        "# Get 300-dim dense vector for each of the 10000 words in out vocabulary\n",
        "embedding_matrix = np.zeros((vocab_size, WORD_EMBEDDING_DIM))\n",
        "for word, i in wordtoix.items():\n",
        "    #if i < max_words:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in the embedding index will be all zeros\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exuFW7YOFggT",
        "colab_type": "text"
      },
      "source": [
        "#For the Inference Notebook\n",
        "##Not needed for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8fQm4YyfNix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #save embedding matrix:\n",
        "# np.save('/content/drive/My Drive/Colab_Notebooks/DL_data/embedding_matrix.npy', embedding_matrix) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m_4EtnggGhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #save dicts needed during inference:\n",
        "# with open('/content/drive/My Drive/Colab_Notebooks/DL_data/ixtoword.json', 'w') as fp:\n",
        "#     json.dump(ixtoword, fp)\n",
        "\n",
        "# with open('/content/drive/My Drive/Colab_Notebooks/DL_data/wordtoix.json', 'w') as fp:\n",
        "#     json.dump(wordtoix, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfq2bjxq_WW7",
        "colab_type": "text"
      },
      "source": [
        "#Input and output for the model\n",
        "###X1, X2, X3, y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK8tkr49aQ4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "def all_data(stories_dict, image_embd, wordtoix, max_length, num_of_stories):\n",
        "  X1, X2, X3, y = list(), list(), list(), list()\n",
        "  #to generate X1,X2,X3 and y. ////append-> have a list of image embeds , have a list for curr caption, have sentences embed for previous sentences, next word\n",
        "  #for each story:\n",
        "  for key, lists in stories_dict.items():\n",
        "    #break after retreiving num_of_stories\n",
        "    if num_of_stories <= 0:\n",
        "      break\n",
        "    num_of_stories -= 1\n",
        "    \n",
        "    img_list=lists[0]\n",
        "    img_list_embed=[image_embd[img_id] for img_id in img_list]#[imgtoix[img_id] for img_id in img_list]\n",
        "    prev_list=lists[1].copy()\n",
        "    prev_list.pop()\n",
        "    prev_list.insert(0,'')\n",
        "    in_cap_list = np.zeros((5,max_length))\n",
        "    out_cap_list = np.zeros((5,max_length))\n",
        "    for c in range(5):\n",
        "      prev_embeddings = [wordtoix[word] for word in prev_list[c].split() if word in wordtoix]\n",
        "      prev_list[c] = pad_sequences([prev_embeddings], maxlen=max_length)[0]\n",
        "\n",
        "      cap=lists[1][c]\n",
        "      cap_in = 'startseq ' + cap\n",
        "      cap_out = cap + ' endseq'\n",
        "      seq_in = [wordtoix[word] for word in cap_in.split() if word in wordtoix]\n",
        "      seq_in = pad_sequences([seq_in], maxlen=max_length, padding='post', truncating='post')[0]\n",
        "      seq_out = [wordtoix[word] for word in cap_out.split() if word in wordtoix]\n",
        "      seq_out = pad_sequences([seq_out], maxlen=max_length, padding='post', truncating='post')[0]\n",
        "      if len(cap_out.split()) > max_length:\n",
        "        seq_out[-1]=wordtoix['endseq']\n",
        "      in_cap_list[c] = np.array(seq_in)\n",
        "      out_cap_list[c] = np.array(seq_out)\n",
        "    X1.append(img_list_embed)\n",
        "    X2.append(in_cap_list)\n",
        "    X3.append(prev_list)\n",
        "    y.append(np.concatenate(out_cap_list).ravel())##out_cap_list\n",
        "\n",
        "  return (array(X1), array(X2), array(X3), array(y))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0ZXWjtxxkMG",
        "colab_type": "code",
        "outputId": "ae7f1fff-e38b-45a4-be8f-5723e3477c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "X1,X2,X3,y = all_data(existing_stories, image_embd, wordtoix, MAX_SEQUENCE_LENGTH, 2)\n",
        "\n",
        "print(\"X\")\n",
        "print(X2)\n",
        "print(\"Y\")\n",
        "print(y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            "[[[ 1.  3.  4.  5.  6.  7.  8.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "    0.  0.  0.]\n",
            "  [ 1. 10. 11. 12. 13. 14.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "    0.  0.  0.]\n",
            "  [ 1. 10. 15. 16. 12. 17. 18.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "    0.  0.  0.]\n",
            "  [ 1. 10. 19. 20. 21. 22.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "    0.  0.  0.]\n",
            "  [ 1. 23. 10. 11. 20. 24. 25.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "    0.  0.  0.]]\n",
            "\n",
            " [[ 1. 26. 27. 20. 28. 29. 30. 31. 32. 33. 28.  6.  9.  0.  0.  0.  0.\n",
            "    0.  0.  0.]\n",
            "  [ 1. 28. 34. 20. 35. 36. 31. 14. 37. 38. 39. 40. 41. 42. 43. 30. 34.\n",
            "    9.  0.  0.]\n",
            "  [ 1. 14. 44. 45. 46. 45. 47. 48. 49. 31. 50. 14.  9.  0.  0.  0.  0.\n",
            "    0.  0.  0.]\n",
            "  [ 1. 31. 51. 42. 21. 45. 52.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "    0.  0.  0.]\n",
            "  [ 1. 53. 54. 55. 56. 57. 36. 58. 31. 50. 59.  9.  0.  0.  0.  0.  0.\n",
            "    0.  0.  0.]]]\n",
            "Y\n",
            "[[ 3.  4.  5.  6.  7.  8.  9.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0. 10. 11. 12. 13. 14.  9.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0. 10. 15. 16. 12. 17. 18.  9.  2.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.  0.  0. 10. 19. 20. 21. 22.  9.  2.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.  0.  0.  0.  0. 23. 10. 11. 20. 24. 25.  9.  2.  0.  0.\n",
            "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [26. 27. 20. 28. 29. 30. 31. 32. 33. 28.  6.  9.  2.  0.  0.  0.  0.  0.\n",
            "   0.  0. 28. 34. 20. 35. 36. 31. 14. 37. 38. 39. 40. 41. 42. 43. 30. 34.\n",
            "   9.  2.  0.  0. 14. 44. 45. 46. 45. 47. 48. 49. 31. 50. 14.  9.  2.  0.\n",
            "   0.  0.  0.  0.  0.  0. 31. 51. 42. 21. 45. 52.  9.  2.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.  0.  0.  0.  0. 53. 54. 55. 56. 57. 36. 58. 31. 50. 59.\n",
            "   9.  2.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSm7P42Yy-Kp",
        "colab_type": "code",
        "outputId": "28b2b96c-54a7-4dba-e4d5-952bdb4c9a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print(np.shape(y))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rpo33OpBdU2L"
      },
      "source": [
        "#Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IaC1BgwxdZsM",
        "colab": {}
      },
      "source": [
        "# # Things I should try:\n",
        "# # 1- bidirectional\n",
        "# # 2- return sequences and merge the two layers\n",
        "# # 3- must get good results on validation (the model must be generalizable)\n",
        "# # 4- modify hyper parameters (hidden layers, batch size, learning rate) (with larger batch size we can use larger learning rate)\n",
        "\n",
        "\n",
        "from keras.regularizers import l2, l1\n",
        "from keras import backend as K\n",
        "def sparse_cross_entropy(y_true, y_pred):\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n",
        "    loss_mean = tf.reduce_mean(loss)\n",
        "    return loss_mean\n",
        "\n",
        "# def custom_sparse_categorical_accuracy(y_true, y_pred):\n",
        "#     return K.cast(K.equal(K.max(y_true, axis=-1),\n",
        "#                           K.cast(K.argmax(y_pred, axis=-1), K.floatx())),K.floatx())\n",
        "def build_model():\n",
        "###slice = Lambda(lambda x: x[:, i])(input)\n",
        "    #Image Encoder\n",
        "    img_input = Input(shape=(5,IMAGE_EMBEDDING_DIM))\n",
        "    img_encoder = GRU(300, return_sequences=True)(img_input) ##might add another layer\n",
        "    img1_enc = Lambda(lambda x: x[:, 0, :])(img_encoder)\n",
        "    img2_enc = Lambda(lambda x: x[:, 1, :])(img_encoder)\n",
        "    img3_enc = Lambda(lambda x: x[:, 2, :])(img_encoder)\n",
        "    img4_enc = Lambda(lambda x: x[:, 3, :])(img_encoder)\n",
        "    img5_enc = Lambda(lambda x: x[:, 4, :])(img_encoder)\n",
        "    #Concatenate()([forward_h, backward_h])\n",
        "\n",
        "    #Previous Sentences Encoder\n",
        "    prev_sents_input = Input(shape=(5,MAX_SEQUENCE_LENGTH))\n",
        "    sent1_in = Lambda(lambda x: x[:, 0, :])(prev_sents_input)\n",
        "    sent2_in = Lambda(lambda x: x[:, 1, :])(prev_sents_input)\n",
        "    sent3_in = Lambda(lambda x: x[:, 2, :])(prev_sents_input)\n",
        "    sent4_in = Lambda(lambda x: x[:, 3, :])(prev_sents_input)\n",
        "    sent5_in = Lambda(lambda x: x[:, 4, :])(prev_sents_input)\n",
        "    \n",
        "    #Embed each:\n",
        "    Word_Embedder = Embedding(vocab_size, WORD_EMBEDDING_DIM, mask_zero=True, weights=[embedding_matrix], trainable=False)\n",
        "    sent1_emb = Word_Embedder(sent1_in)\n",
        "    sent2_emb = Word_Embedder(sent2_in)\n",
        "    sent3_emb = Word_Embedder(sent3_in)\n",
        "    sent4_emb = Word_Embedder(sent4_in)\n",
        "    sent5_emb = Word_Embedder(sent5_in)\n",
        "    \n",
        "    #define previouse sentences encoder:\n",
        "    prev_encoder = GRU(100, recurrent_dropout=0, dropout=0.0 , return_sequences=False, activity_regularizer=l2(0.000))\n",
        "\n",
        "    #now use the encoder:\n",
        "    sent1_enc = prev_encoder(sent1_emb)\n",
        "    sent2_enc = prev_encoder(sent2_emb , initial_state = sent1_enc)\n",
        "    sent3_enc = prev_encoder(sent3_emb , initial_state = sent2_enc)\n",
        "    sent4_enc = prev_encoder(sent4_emb , initial_state = sent3_enc)\n",
        "    sent5_enc = prev_encoder(sent5_emb , initial_state = sent4_enc)\n",
        "\n",
        "\n",
        "    #now prepare for decoder:\n",
        "    hidden_1 = concatenate([sent1_enc,img1_enc])\n",
        "    hidden_2 = concatenate([sent2_enc,img2_enc])\n",
        "    hidden_3 = concatenate([sent3_enc,img3_enc])\n",
        "    hidden_4 = concatenate([sent4_enc,img4_enc])\n",
        "    hidden_5 = concatenate([sent5_enc,img5_enc])\n",
        "\n",
        "    #Decoder:\n",
        "    decoder = GRU(400,recurrent_dropout=0, dropout=0.0 ,return_sequences=True ,activity_regularizer=l2(0.000))\n",
        "    \n",
        "    #Current captions\n",
        "    captions_input = Input(shape=(5,MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "    #split\n",
        "    cap1_in = Lambda(lambda x: x[:, 0, :])(captions_input)\n",
        "    cap2_in = Lambda(lambda x: x[:, 1, :])(captions_input)\n",
        "    cap3_in = Lambda(lambda x: x[:, 2, :])(captions_input)\n",
        "    cap4_in = Lambda(lambda x: x[:, 3, :])(captions_input)\n",
        "    cap5_in = Lambda(lambda x: x[:, 4, :])(captions_input)\n",
        "    \n",
        "    #Embed each:\n",
        "    cap1_emb = Word_Embedder(cap1_in)\n",
        "    cap2_emb = Word_Embedder(cap2_in)\n",
        "    cap3_emb = Word_Embedder(cap3_in)\n",
        "    cap4_emb = Word_Embedder(cap4_in)\n",
        "    cap5_emb = Word_Embedder(cap5_in)\n",
        "\n",
        "    #Decode\n",
        "    cap1_dec = decoder(cap1_emb , initial_state = hidden_1)\n",
        "    cap2_dec = decoder(cap2_emb , initial_state = hidden_2)\n",
        "    cap3_dec = decoder(cap3_emb , initial_state = hidden_3)\n",
        "    cap4_dec = decoder(cap4_emb , initial_state = hidden_4)\n",
        "    cap5_dec = decoder(cap5_emb , initial_state = hidden_5)\n",
        "\n",
        "    decoder_out = concatenate([cap1_dec, cap2_dec, cap3_dec, cap4_dec, cap5_dec], axis=-2)\n",
        "\n",
        "    decoder_dense = Dense(200, activation=None, kernel_regularizer=l2(0.000))(decoder_out)\n",
        "    outputs = Dense(vocab_size, activation='linear')(decoder_dense) ##was softmax /// used linear because it's recommended with the custom loss: https://github.com/tensorflow/tensorflow/issues/17150\n",
        "    model = Model(inputs=[img_input, captions_input, prev_sents_input], outputs=outputs)\n",
        "\n",
        "    model.summary()\n",
        "    decoder_target = tf.placeholder(dtype='int32', shape=(None, None))\n",
        "    model.compile(loss=sparse_cross_entropy, optimizer='adam', target_tensors=[decoder_target])#'adam') #, target_tensors=[decoder_target]\n",
        "#'sparse_categorical_crossentropy'\n",
        "#tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# metrics=[custom_sparse_categorical_accuracy]\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aCFNBmPWdZ71"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z9RFuY7wfx4t",
        "outputId": "2aee52e3-eb51-4366-c19f-727c062b5583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_model()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 5, 20)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 5, 20)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_26 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_21 (Lambda)              (None, 20)           0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 20, 300)      7971600     lambda_21[0][0]                  \n",
            "                                                                 lambda_22[0][0]                  \n",
            "                                                                 lambda_23[0][0]                  \n",
            "                                                                 lambda_24[0][0]                  \n",
            "                                                                 lambda_25[0][0]                  \n",
            "                                                                 lambda_26[0][0]                  \n",
            "                                                                 lambda_27[0][0]                  \n",
            "                                                                 lambda_28[0][0]                  \n",
            "                                                                 lambda_29[0][0]                  \n",
            "                                                                 lambda_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_27 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_22 (Lambda)              (None, 20)           0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_5 (GRU)                     (None, 100)          120300      embedding_2[0][0]                \n",
            "                                                                 embedding_2[1][0]                \n",
            "                                                                 gru_5[0][0]                      \n",
            "                                                                 embedding_2[2][0]                \n",
            "                                                                 gru_5[1][0]                      \n",
            "                                                                 embedding_2[3][0]                \n",
            "                                                                 gru_5[2][0]                      \n",
            "                                                                 embedding_2[4][0]                \n",
            "                                                                 gru_5[3][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_28 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_23 (Lambda)              (None, 20)           0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_29 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_24 (Lambda)              (None, 20)           0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 5, 2048)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_30 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_25 (Lambda)              (None, 20)           0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_4 (GRU)                     (None, 5, 300)       2114100     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 300)          0           gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 300)          0           gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 300)          0           gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 300)          0           gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 300)          0           gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 400)          0           gru_5[0][0]                      \n",
            "                                                                 lambda_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 400)          0           gru_5[1][0]                      \n",
            "                                                                 lambda_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 400)          0           gru_5[2][0]                      \n",
            "                                                                 lambda_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 400)          0           gru_5[3][0]                      \n",
            "                                                                 lambda_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 400)          0           gru_5[4][0]                      \n",
            "                                                                 lambda_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gru_6 (GRU)                     (None, 20, 400)      841200      embedding_2[5][0]                \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 embedding_2[6][0]                \n",
            "                                                                 concatenate_8[0][0]              \n",
            "                                                                 embedding_2[7][0]                \n",
            "                                                                 concatenate_9[0][0]              \n",
            "                                                                 embedding_2[8][0]                \n",
            "                                                                 concatenate_10[0][0]             \n",
            "                                                                 embedding_2[9][0]                \n",
            "                                                                 concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 100, 400)     0           gru_6[0][0]                      \n",
            "                                                                 gru_6[1][0]                      \n",
            "                                                                 gru_6[2][0]                      \n",
            "                                                                 gru_6[3][0]                      \n",
            "                                                                 gru_6[4][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100, 200)     80200       concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 100, 26572)   5340972     dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 16,468,372\n",
            "Trainable params: 8,496,772\n",
            "Non-trainable params: 7,971,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V620wYUxnhZh",
        "colab_type": "text"
      },
      "source": [
        "#Or load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si6PjcblnmDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = load_model('/content/drive/My Drive/Colab_Notebooks/DL_data/models/final_model_basic_100_stories_checkpoint-ep033-loss3.835.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUVRiOtMJCk0",
        "colab_type": "text"
      },
      "source": [
        "#Prep Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR4FhSY2cW1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1,X2,X3,y = all_data(existing_stories, image_embd, wordtoix, MAX_SEQUENCE_LENGTH, 25)#35565\n",
        "#for GCP\n",
        "filepath_checkpoint = \"final_model_all_stories-ep{epoch:03d}-loss{loss:.3f}.h5\"\n",
        "filepath_model = 'final_model_all_stories_finale.h5'\n",
        "\n",
        "# # #for Colab\n",
        "# filepath_checkpoint = \"/content/drive/My Drive/Colab_Notebooks/DL_data/models/Suggested_10_-ep{epoch:03d}-loss{loss:.3f}.h5\"\n",
        "# filepath_model = '/content/drive/My Drive/Colab_Notebooks/DL_data/models/Suggested_10_epoch1.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUcqBAeVLQdB",
        "colab_type": "text"
      },
      "source": [
        "#Training\n",
        "##HERE I'm testing with only 25 examples, so yeah overfitting\n",
        "###You can run for the entire dataset, add dropout and regularization if overfitting is happening (data is big so not much overfitting tbh)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soHPqZiKLSHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e227835f-9125-4468-e704-893f0f0c42ec"
      },
      "source": [
        "#checkpoint = ModelCheckpoint(filepath_checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "history = model.fit([X1,X2,X3], y, epochs=100, verbose=1, batch_size=32, validation_split=0.1, shuffle=True, workers=10, use_multiprocessing=True) #callbacks=[checkpoint]\n",
        "# model.save(filepath_model)\n",
        "# model.save_weights(filepath_w)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 22 samples, validate on 3 samples\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - 8s 368ms/step - loss: 10.1814 - val_loss: 10.0717\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 10.0511 - val_loss: 9.9237\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 9.8796 - val_loss: 9.6799\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 9.5998 - val_loss: 9.2468\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 9.1097 - val_loss: 8.4730\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 8.2474 - val_loss: 7.2245\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 6.8590 - val_loss: 5.7897\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 5.1949 - val_loss: 4.8387\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 3.9741 - val_loss: 4.5418\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 3.4507 - val_loss: 4.7664\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 3.4953 - val_loss: 4.9952\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 3.5882 - val_loss: 5.0516\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 3.5419 - val_loss: 5.0954\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 3.4912 - val_loss: 5.2416\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 3.5292 - val_loss: 5.3711\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 3.5394 - val_loss: 5.4039\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 3.4537 - val_loss: 5.4111\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.3507 - val_loss: 5.4587\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 3.3015 - val_loss: 5.5437\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.3082 - val_loss: 5.6254\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 3.3332 - val_loss: 5.6729\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 3.3466 - val_loss: 5.6807\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.3408 - val_loss: 5.6627\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 3.3207 - val_loss: 5.6327\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 3.2903 - val_loss: 5.5961\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.2547 - val_loss: 5.5612\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 3.2200 - val_loss: 5.5373\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.1950 - val_loss: 5.5260\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 3.1853 - val_loss: 5.5168\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 3.1841 - val_loss: 5.4923\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 3.1794 - val_loss: 5.4497\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 3.1664 - val_loss: 5.4114\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.1476 - val_loss: 5.3887\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.1271 - val_loss: 5.3715\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 3.1094 - val_loss: 5.3462\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.0940 - val_loss: 5.3160\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 3.0801 - val_loss: 5.2970\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.0659 - val_loss: 5.2906\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 3.0505 - val_loss: 5.2842\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 3.0350 - val_loss: 5.2710\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 3.0195 - val_loss: 5.2512\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 3.0040 - val_loss: 5.2289\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.9889 - val_loss: 5.2097\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 2.9741 - val_loss: 5.1945\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 2.9593 - val_loss: 5.1768\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 2.9444 - val_loss: 5.1517\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.9289 - val_loss: 5.1220\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.9131 - val_loss: 5.0954\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 2.8973 - val_loss: 5.0792\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.8818 - val_loss: 5.0651\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.8664 - val_loss: 5.0371\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.8507 - val_loss: 5.0083\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.8347 - val_loss: 4.9974\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.8186 - val_loss: 4.9739\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.8026 - val_loss: 4.9373\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.7862 - val_loss: 4.9221\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.7693 - val_loss: 4.9021\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 2.7526 - val_loss: 4.8656\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.7362 - val_loss: 4.8677\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.7207 - val_loss: 4.8202\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.7057 - val_loss: 4.8436\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 2.6916 - val_loss: 4.7832\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 2.6765 - val_loss: 4.8040\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.6611 - val_loss: 4.7657\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.6451 - val_loss: 4.7415\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.6306 - val_loss: 4.7560\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.6170 - val_loss: 4.7022\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.6022 - val_loss: 4.7067\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.5873 - val_loss: 4.6902\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.5737 - val_loss: 4.6548\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.5608 - val_loss: 4.6716\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.5477 - val_loss: 4.6347\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.5337 - val_loss: 4.6274\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.5204 - val_loss: 4.6352\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 2.5080 - val_loss: 4.5956\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.4959 - val_loss: 4.6302\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.4841 - val_loss: 4.5787\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.4715 - val_loss: 4.6066\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.4589 - val_loss: 4.5783\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.4463 - val_loss: 4.5719\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.4348 - val_loss: 4.5896\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.4242 - val_loss: 4.5497\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.4139 - val_loss: 4.5949\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.4039 - val_loss: 4.5459\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.3918 - val_loss: 4.5648\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.3798 - val_loss: 4.5700\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.3696 - val_loss: 4.5423\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.3603 - val_loss: 4.5845\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.3506 - val_loss: 4.5432\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.3393 - val_loss: 4.5609\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.3281 - val_loss: 4.5676\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 2.3182 - val_loss: 4.5440\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.3090 - val_loss: 4.5895\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.2999 - val_loss: 4.5433\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.2891 - val_loss: 4.5773\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.2780 - val_loss: 4.5649\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.2673 - val_loss: 4.5579\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.2578 - val_loss: 4.6036\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.2492 - val_loss: 4.5573\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.2399 - val_loss: 4.6189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FoLOOVLH8Qg",
        "colab_type": "text"
      },
      "source": [
        "#Plot loss curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fu6qxITIplR",
        "colab_type": "code",
        "outputId": "f6d3b4bf-b50f-4891-b9fe-5f883d3595d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.legend(['validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__PdIIMSLoST",
        "colab_type": "text"
      },
      "source": [
        "#Another 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92qmH20gLq7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db7b8402-f19e-41b3-d164-ec5757038b88"
      },
      "source": [
        "history = model.fit([X1,X2,X3], y, epochs=100, verbose=1, batch_size=32, validation_split=0.1, shuffle=True, workers=10, use_multiprocessing=True) #callbacks=[checkpoint]\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 22 samples, validate on 3 samples\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.2303 - val_loss: 4.5724\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 2.2182 - val_loss: 4.5970\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.2067 - val_loss: 4.6193\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.1971 - val_loss: 4.5896\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.1885 - val_loss: 4.6611\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.1803 - val_loss: 4.5947\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.1694 - val_loss: 4.6526\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.1569 - val_loss: 4.6381\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.1445 - val_loss: 4.6290\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.1356 - val_loss: 4.7023\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.1279 - val_loss: 4.6316\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.1168 - val_loss: 4.6933\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.1036 - val_loss: 4.6783\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.0905 - val_loss: 4.6669\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.0815 - val_loss: 4.7493\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.0738 - val_loss: 4.6790\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 2.0609 - val_loss: 4.7299\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.0468 - val_loss: 4.7337\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 2.0349 - val_loss: 4.7139\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.0257 - val_loss: 4.7900\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.0158 - val_loss: 4.7393\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.0018 - val_loss: 4.7731\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.9884 - val_loss: 4.7972\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.9773 - val_loss: 4.7733\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 1.9672 - val_loss: 4.8449\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.9564 - val_loss: 4.7967\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.9431 - val_loss: 4.8436\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.9294 - val_loss: 4.8484\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.9166 - val_loss: 4.8432\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.9057 - val_loss: 4.9051\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.8953 - val_loss: 4.8593\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.8833 - val_loss: 4.9218\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.8702 - val_loss: 4.8999\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.8557 - val_loss: 4.9217\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 1.8432 - val_loss: 4.9604\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.8319 - val_loss: 4.9325\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.8210 - val_loss: 4.9990\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.8095 - val_loss: 4.9634\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.7958 - val_loss: 5.0151\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.7820 - val_loss: 5.0111\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.7685 - val_loss: 5.0213\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.7566 - val_loss: 5.0682\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.7454 - val_loss: 5.0440\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.7343 - val_loss: 5.1088\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.7230 - val_loss: 5.0703\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.7103 - val_loss: 5.1299\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.6964 - val_loss: 5.1231\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.6827 - val_loss: 5.1423\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.6703 - val_loss: 5.1817\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.6593 - val_loss: 5.1634\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.6479 - val_loss: 5.2213\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.6357 - val_loss: 5.2023\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 1.6225 - val_loss: 5.2428\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.6094 - val_loss: 5.2574\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.5968 - val_loss: 5.2664\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.5850 - val_loss: 5.3093\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.5734 - val_loss: 5.2915\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.5619 - val_loss: 5.3498\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.5496 - val_loss: 5.3310\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.5371 - val_loss: 5.3829\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.5239 - val_loss: 5.3796\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.5107 - val_loss: 5.4060\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.4980 - val_loss: 5.4336\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 1.4858 - val_loss: 5.4316\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.4738 - val_loss: 5.4796\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.4617 - val_loss: 5.4660\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.4496 - val_loss: 5.5229\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.4373 - val_loss: 5.5026\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.4247 - val_loss: 5.5622\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.4115 - val_loss: 5.5495\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.3979 - val_loss: 5.5874\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.3843 - val_loss: 5.6061\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 1.3713 - val_loss: 5.6161\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.3588 - val_loss: 5.6604\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.3464 - val_loss: 5.6510\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.3341 - val_loss: 5.7084\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.3213 - val_loss: 5.6925\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.3081 - val_loss: 5.7474\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 1.2943 - val_loss: 5.7459\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.2804 - val_loss: 5.7803\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.2667 - val_loss: 5.8033\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.2534 - val_loss: 5.8139\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.2405 - val_loss: 5.8571\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.2276 - val_loss: 5.8532\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.2149 - val_loss: 5.9108\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.2019 - val_loss: 5.8962\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.1891 - val_loss: 5.9579\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.1754 - val_loss: 5.9460\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.1614 - val_loss: 5.9951\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.1471 - val_loss: 6.0092\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.1332 - val_loss: 6.0277\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.1201 - val_loss: 6.0708\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 1.1075 - val_loss: 6.0675\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.0949 - val_loss: 6.1242\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.0817 - val_loss: 6.1177\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.0684 - val_loss: 6.1698\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.0545 - val_loss: 6.1755\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 1.0408 - val_loss: 6.2072\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.0275 - val_loss: 6.2385\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.0147 - val_loss: 6.2463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fsSx4SPhK1b",
        "colab_type": "code",
        "outputId": "610b6729-3401-4527-f786-cd137dfcaee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "print(y[10])\n",
        "x1 = X1[10]\n",
        "x2 = X2[10]\n",
        "x3 = X3[10]\n",
        "tmp=''\n",
        "for w in y[10]:\n",
        "  if w in ixtoword:\n",
        "    if w == 'endseq': continue\n",
        "    tmp += ' ' + ixtoword[w]\n",
        "print(tmp)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 31. 221. 222.   7.  31. 223. 224.   9.   2.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.  31. 225.  72. 226. 227.   9.   2.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  62. 228.\n",
            "   7. 229.   9.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.  62. 230.  16.  62. 231. 232.   5.  31. 233. 234.\n",
            " 137.   2.   0.   0.   0.   0.   0.   0.   0.   0. 100.  80.  68.  93.\n",
            "  62. 152.   9.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.]\n",
            " the fish pond was the main attraction . endseq the flowers were also pretty . endseq this bug was interesting . endseq this women made this kid go to the plant garden , endseq time for fun on this ride . endseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Kz14jsimQV",
        "colab_type": "code",
        "outputId": "38012dce-9171-4998-c4e9-e7c8b0348f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "yhat = model.predict([x1[np.newaxis,...],x2[np.newaxis,...],x3[np.newaxis,...]], verbose=0)\n",
        "yhat_s = yhat[0,:,:]\n",
        "print(yhat_s.shape)\n",
        "print(np.argmax(yhat_s, axis=-1))\n",
        "tmp=''\n",
        "for w in np.argmax(yhat_s, axis=-1):\n",
        "  if w in ixtoword:\n",
        "    if w == 'endseq': continue\n",
        "    tmp += ' ' + ixtoword[w]\n",
        "print(tmp)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 26572)\n",
            "[ 31 278   7   7  31 223 224   9   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  31 225  72 226 227   9   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  23 228   7 229   9   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0  10 103  16  78 231 232  30  31 233   9   9   0\n",
            "   0   0   0   0   0   0   0   0  31  20  20  49  31  68   9   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            " the two was was the main attraction . the flowers were also pretty . then bug was interesting . i temple made us kid go in the plant . . the a a with the fun .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR7eneAV-Fos",
        "colab_type": "text"
      },
      "source": [
        "#TRY validation:\n",
        "Not real validation as I'm using the actual the training set (but just want to confirm that it produces same thing)\n",
        "However, apparently, it is suffering if it produces one wrong word (result before this are conditioned on the right words, that is why it is producing something similar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfzGfkAc-Iub",
        "colab_type": "code",
        "outputId": "1c4516fc-0351-44ca-9a19-3a1145ddfb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage.interpolation import shift\n",
        "#X1: 1x5x2048 --images\n",
        "#X2: 1x5x20  --captions\n",
        "#X3: 1x5x20    --prev\n",
        "index_v = 10\n",
        "x1_v = X1[index_v]\n",
        "x2_v = np.zeros_like(X2[index_v])\n",
        "x3_v = np.zeros_like(X3[index_v])\n",
        "for i in range(5):\n",
        "  x2_v[i][0] = wordtoix['startseq']\n",
        "  for j in range(MAX_SEQUENCE_LENGTH-1):\n",
        "    yhat = model.predict([x1_v[np.newaxis,...],x2_v[np.newaxis,...],x3_v[np.newaxis,...]], verbose=0)\n",
        "    yhat_s = yhat[0,:,:]\n",
        "    x2_v[i][j+1] = np.argmax(yhat_s, axis=-1)[j]\n",
        "  x3_v[i] = x2_v[i]\n",
        "  x3_v[i] = shift(x3_v[i], 1, cval=0)\n",
        "\n",
        "print(x3_v)\n",
        "print(x2_v)\n",
        "x2_v = np.concatenate(x2_v).ravel()\n",
        "x3_v = np.concatenate(x3_v).ravel()\n",
        "\n",
        "caps=''\n",
        "for w in x2_v:\n",
        "  if w in ixtoword:\n",
        "    if ixtoword[w] == 'startseq' or ixtoword[w] =='endseq': continue\n",
        "    caps += \" \" + ixtoword[w]\n",
        "print(\"Captions:\")\n",
        "print(caps)\n",
        "      \n",
        "s=''\n",
        "for w in x3_v:\n",
        "  if w in ixtoword:\n",
        "    #if ixtoword[w] == 'startseq' or ixtoword[w] =='endseq': continue\n",
        "    s += \" \"+ ixtoword[w]\n",
        "print(\"Sentences:\")\n",
        "print(s)\n",
        "\n",
        "\n",
        "print(\"Original\") #X3[1]\n",
        "or_f = np.concatenate(X2[index_v]).ravel()\n",
        "o=''\n",
        "for w in or_f:\n",
        "  if w in ixtoword:\n",
        "    if ixtoword[w] == 'startseq' or ixtoword[w] =='endseq': continue\n",
        "    o += \" \"+ ixtoword[w]\n",
        "\n",
        "print(o)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   1  31 278 221 222   7   8   9   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  0   1  60 225  72 331   9   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  0   1  60 225  72 331   9   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  0   1  60 225  72 331   9   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  0   1  60 225  72 331   9   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "[[  1.  31. 278. 221. 222.   7.   8.   9.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.]\n",
            " [  1.  60. 225.  72. 331.   9.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.]\n",
            " [  1.  60. 225.  72. 331.   9.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.]\n",
            " [  1.  60. 225.  72. 331.   9.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.]\n",
            " [  1.  60. 225.  72. 331.   9.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.]]\n",
            "Captions:\n",
            " the two fish pond was amazing . we flowers were parrots . we flowers were parrots . we flowers were parrots . we flowers were parrots .\n",
            "Sentences:\n",
            " startseq the two fish pond was amazing . startseq we flowers were parrots . startseq we flowers were parrots . startseq we flowers were parrots . startseq we flowers were parrots .\n",
            "Original\n",
            " the fish pond was the main attraction . the flowers were also pretty . this bug was interesting . this women made this kid go to the plant garden , time for fun on this ride .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
