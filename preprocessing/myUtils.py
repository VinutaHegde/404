import numpy as np
import tensorflow as tf
from tensorflow.keras.backend import eval

from absl import logging

import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import re
import seaborn as sns

class functions(object):
    """Computes and stores the average and current value"""

    def __init__(self):
        return

    def sim_np(embed1, embed2):
        return np.dot(embed1,embed2) / (np.linalg.norm(embed1,ord=2) * np.linalg.norm(embed2,ord=2))
    #for tensors:
    def sim_tensor(embed1,embed2):
        return tf.tensordot(embed1,embed2,axes=1)/(tf.norm(embed1,ord=2)*tf.norm(embed2,ord=2))

    def get_embedding_matrix(filename, EMBEDDING_DIM):
        embeddings_index = {}
        word_to_index = {}

        with open(filename) as f:
            for index, line in enumerate(f):
                values = line.split()
                word = values[0]
                coefs = np.asarray(values[1:], dtype='float32')
                embeddings_index[word] = coefs
                word_to_index[word] = index

          # Vocabulary
        vocabulary = embeddings_index.keys()
        embedding_matrix = np.zeros((len(vocabulary) + 1, EMBEDDING_DIM))

        for word, i in word_to_index.items():
            embedding_vector = embeddings_index[word]
            if embedding_vector is not None:
                embedding_matrix[i] = embedding_vector

        return embedding_matrix, vocabulary, word_to_index

    def load_tf_embedding_model():
        module_url = "https://tfhub.dev/google/universal-sentence-encoder/2" 
        embed = hub.Module(module_url)
        return embed
    
    def get_sentence_embedding(embed,sentences):
        with tf.Session() as session:
            session.run([tf.global_variables_initializer(), tf.tables_initializer()])
            message_embeddings = session.run(embed(sentences))
            print(message_embeddings)
            return message_embeddings

if __name__ == '__main__':
    #Example usage (2 embeddings)
    embed1=np.array(("0.04656 0.21318 -0.0074364 -0.45854 -0.035639 0.23643 -0.28836 0.21521 -0.13486 -1.6413 -0.26091 0.032434\
     0.056621 -0.043296 -0.021672 0.22476 -0.075129 -0.067018 -0.14247 0.038825 -0.18951 0.29977 0.39305 0.17887 -0.17343 -0.21178\
      0.23617 -0.063681 -0.42318 -0.11661 0.093754 0.17296 -0.33073 0.49112 -0.68995 -0.092462 0.24742 -0.17991 0.097908 0.083118\
       0.15299 -0.27276 -0.038934 0.54453 0.53737 0.29105 -0.0073514 0.04788 -0.4076 -0.026759 0.17919 0.010977 -0.10963 -0.26395\
        0.07399 0.26236 -0.1508 0.34623 0.25758 0.11971 -0.037135 -0.071593 0.43898 -0.040764 0.016425 -0.4464 0.17197 0.046246 0.058639\
         0.041499 0.53948 0.52495 0.11361 -0.048315 -0.36385 0.18704 0.092761 -0.11129 -0.42085 0.13992 -0.39338 -0.067945 0.12188 0.16707\
          0.075169 -0.015529 -0.19499 0.19638 0.053194 0.2517 -0.34845 -0.10638 -0.34692 -0.19024 -0.2004 0.12154 -0.29208 0.023353 -0.11618\
           -0.35768 0.062304 0.35884 0.02906 0.0073005 0.0049482 -0.15048 -0.12313 0.19337 0.12173 0.44503 0.25147 0.10781 -0.17716 0.038691\
            0.08153 0.14667 0.063666 0.061332 -0.075569 -0.37724 0.01585 -0.30342 0.28374 -0.042013 -0.040715 -0.15269 0.07498 0.15577 0.10433\
             0.31393 0.19309 0.19429 0.15185 -0.10192 -0.018785 0.20791 0.13366 0.19038 -0.25558 0.304 -0.01896 0.20147 -0.4211 -0.0075156 -0.27977\
              -0.19314 0.046204 0.19971 -0.30207 0.25735 0.68107 -0.19409 0.23984 0.22493 0.65224 -0.13561 -0.17383 -0.048209 -0.1186 0.0021588 -0.019525\
               0.11948 0.19346 -0.4082 -0.082966 0.16626 -0.10601 0.35861 0.16922 0.07259 -0.24803 -0.10024 -0.52491 -0.17745 -0.36647 0.2618 -0.012077\
                0.08319 -0.21528 0.41045 0.29136 0.30869 0.078864 0.32207 -0.041023 -0.1097 -0.092041 -0.12339 -0.16416 0.35382 -0.082774 0.33171 -0.24738\
                 -0.048928 0.15746 0.18988 -0.026642 0.063315 -0.010673 0.34089 1.4106 0.13417 0.28191 -0.2594 0.055267 -0.052425 -0.25789 0.019127 -0.022084\
                  0.32113 0.068818 0.51207 0.16478 -0.20194 0.29232 0.098575 0.013145 -0.10652 0.1351 -0.045332 0.20697 -0.48425 -0.44706 0.0033305 0.0029264 \
                  -0.10975 -0.23325 0.22442 -0.10503 0.12339 0.10978 0.048994 -0.25157 0.40319 0.35318 0.18651 -0.023622 -0.12734 0.11475 0.27359 -0.21866 0.015794\
                   0.81754 -0.023792 -0.85469 -0.16203 0.18076 0.028014 -0.1434 0.0013139 -0.091735 -0.089704 0.11105 -0.16703 0.068377 -0.087388 -0.039789 0.014184\
                    0.21187 0.28579 -0.28797 -0.058996 -0.032436 -0.0047009 -0.17052 -0.034741 -0.11489 0.075093 0.099526 0.048183 -0.073775 -0.41817 0.0041268 0.44414\
                     -0.16062 0.14294 -2.2628 -0.027347 0.81311 0.77417 -0.25639 -0.11576 -0.11982 -0.21363 0.028429 0.27261 0.031026 0.096782 0.0067769 0.14082\
                      -0.013064 -0.29686 -0.079913 0.195 0.031549 0.28506 -0.087461 0.0090611 -0.20989 \
                      0.053913").split()).astype(np.float)
    embed2=np.array(("-0.25756 -0.057132 -0.6719 -0.38082 -0.36421 -0.082155 -0.010955 -0.082047 0.46056 -1.8477 -0.11258 -0.12955 0.27254 0.0072891\
     0.26038 0.12096 -0.23193 0.03226 -0.29472 -0.67594 -0.33844 -0.23297 0.1102 0.18816 -0.45184 -0.33833 0.11274 0.4949 -0.042132 0.079961 -0.013146\
      0.062284 0.20223 0.038279 -1.1154 -0.1214 0.089846 0.29702 -0.055794 -0.46021 -0.13194 0.087357 -0.27865 0.14981 0.25536 0.16698 -0.04452 0.067588\
       -0.11772 -0.13452 0.28694 -0.39844 -0.12806 -0.47818 0.067802 0.20353 -0.30677 0.60789 -0.18588 0.11997 -0.040508 -0.06586 0.30621 -0.055824 0.039448\
        -0.4557 0.21081 0.25889 0.14666 0.3095 0.14343 0.10524 0.15788 0.103 0.32211 -0.27939 -0.17139 0.32202 0.10784 -0.28209 0.12611 -0.23913 -0.089638\
         -0.39179 -0.26402 0.36796 -0.23691 0.62503 -0.027226 -0.038851 -0.37359 0.045442 -0.17169 -0.54477 -0.091772 -0.32952 -0.25522 0.087106 0.048685\
          -0.31684 -0.064198 0.044885 -0.49587 0.429 0.36198 -0.14682 0.20122 -0.030038 0.18736 0.31626 0.059023 -0.13473 -0.40664 -0.52983 0.072459 0.082531\
           -0.32495 -0.006691 0.43564 -0.12976 -0.26293 0.15975 0.25062 -0.064732 -0.30689 0.16084 0.4583 0.38565 0.12612 -0.00080485 0.18055 0.24757 0.5568\
            0.21701 0.33105 0.11991 0.0027257 -0.10679 -0.16922 0.25277 0.36024 -0.4762 -0.20035 0.38473 -0.71653 -0.13788 -0.12201 -0.16979 -0.29624\
             -0.010344 0.19216 0.063375 0.30977 -0.19759 0.57419 0.34018 -0.34795 -0.085304 -0.028243 -0.39182 0.23797 -0.092997 0.11981 -0.2368 0.098179\
              0.083047 0.12652 0.16026 -0.14166 0.14296 -0.12868 0.18181 -0.42337 0.18061 -0.051635 -0.17987 -0.097071 0.0013755 -0.42539 0.56817 0.057432\
               0.31577 0.18918 0.27639 -0.39906 0.18594 -0.54231 0.61376 0.37921 0.1366 -0.39842 0.58557 0.054558 0.061801 0.32546 -0.19615 -0.034329\
                -0.013225 0.67854 -0.16672 0.92439 0.11952 0.040351 0.35368 -0.25573 0.26648 -0.020954 0.18535 0.062376 -0.22976 -0.074563 -0.3289 0.28535\
                 0.46959 -0.54324 0.14124 0.19964 0.1541 0.024155 0.144 0.30989 -0.15989 -0.11611 0.09102 -0.50317 -0.33662 0.059168 0.43838 -0.1428\
                  -0.0053718 0.046505 0.21546 0.065006 -0.35175 -0.17137 0.20467 -0.07173 0.40879 0.20295 -0.014211 -0.21898 -0.12831 0.3224 0.17608\
                   -0.60267 0.036737 0.54848 -0.47682 -0.56556 -0.083633 0.032302 -0.25262 0.39481 -0.019623 0.62547 -0.11369 -0.25727 0.073363 0.18437\
                    0.14587 0.32708 -0.52049 0.037555 0.023667 -0.068237 -0.22916 0.017755 -0.18394 0.55107 -0.23965 0.39187 -0.017785 0.43113 0.27181\
                     -0.16043 -0.347 -2.4194 -0.028952 0.95085 0.05804 -0.23623 0.18914 0.31192 0.23064 -0.30309 -0.18603 0.07618 0.37337 -0.14444 -0.028793\
                      -0.012806 -0.59707 0.31734 -0.25267 0.54384 0.063007 -0.049795 -0.16043 0.046744\
                       -0.070621").split()).astype(np.float)

    #numpy arrays
    result=sim_np(embed1,embed2)
    print(eval(result))

    #tensors
    embed1=tf.convert_to_tensor(embed1,dtype=float)
    embed2=tf.convert_to_tensor(embed2,dtype=float)
    result=sim_tensor(embed1,embed2)
    print(eval(result))