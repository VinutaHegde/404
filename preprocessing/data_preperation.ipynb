{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from myUtils import functions\n",
    "import copy\n",
    "import numpy as np\n",
    "import re\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from skimage.transform import rescale, resize\n",
    "from skimage import data, color, io\n",
    "import skimage\n",
    "import PIL \n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "WORD_EMBEDDING_DIM = 300\n",
    "MAX_SENTANCE_DIM = 92 # TODO: update considering all the captions in the dataset\n",
    "MAX_PARAGRAPH_DIM = 5\n",
    "EMBEDDING_FILE_NAME = 'glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_encoder:\n",
    "    \n",
    "    def load_embedings(self):\n",
    "        embedding_matrix, vocabulary, word_to_index = functions.get_embedding_matrix(EMBEDDING_FILE_NAME, WORD_EMBEDDING_DIM)      \n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.vocabulary = vocabulary\n",
    "        self.word_to_index = word_to_index\n",
    "        \n",
    "    def get_sentence_embedding(self,sentence):\n",
    "        words = sentence.split()    \n",
    "        sentance_embedding =  np.zeros(shape=(MAX_SENTANCE_DIM,WORD_EMBEDDING_DIM))\n",
    "        mask =  np.zeros(MAX_SENTANCE_DIM)\n",
    "        i=0;\n",
    "        for w in words:\n",
    "            mask[i] = 1\n",
    "            index = self.word_to_index.get(w,-1)\n",
    "            if(index != -1):\n",
    "                sentance_embedding[i] = self.embedding_matrix[index]\n",
    "            else:\n",
    "                sentance_embedding[i] = np.zeros(WORD_EMBEDDING_DIM)\n",
    "            i+=1       \n",
    "        return  sentance_embedding, mask\n",
    "    \n",
    "    def preprocess_paragraph(self, paragraph):\n",
    "        pat = re.compile(r\"([()!',;:?])\")\n",
    "        processed_paragraph = pat.sub(\" \\\\1\", paragraph)\n",
    "        return processed_paragraph\n",
    "       \n",
    "    def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"i'm\", \"i am\", text)\n",
    "        text = re.sub(r\"he's\", \"he is\", text)\n",
    "        text = re.sub(r\"she's\", \"she is\", text)\n",
    "        text = re.sub(r\"it's\", \"it is\", text)\n",
    "        text = re.sub(r\"that's\", \"that is\", text)\n",
    "        text = re.sub(r\"what's\", \"that is\", text)\n",
    "        text = re.sub(r\"where's\", \"where is\", text)\n",
    "        text = re.sub(r\"how's\", \"how is\", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"can't\", \"cannot\", text)\n",
    "        text = re.sub(r\"n't\", \" not\", text)\n",
    "        text = re.sub(r\"n'\", \"ng\", text)\n",
    "        text = re.sub(r\"'bout\", \"about\", text)\n",
    "        text = re.sub(r\"'til\", \"until\", text)\n",
    "        text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "        return text\n",
    "    \n",
    "    def get_paragraph_embedding(self, paragraph):\n",
    "        sentences = paragraph.split(\".\")\n",
    "        paragraph_embedding = np.zeros(shape=(MAX_PARAGRAPH_DIM,MAX_SENTANCE_DIM,WORD_EMBEDDING_DIM))\n",
    "        paragraph_mask = np.zeros(shape=(MAX_PARAGRAPH_DIM,MAX_SENTANCE_DIM))\n",
    "        i = 0;\n",
    "        for s in sentences:\n",
    "            processed_sentence = self.preprocess_paragraph(s.strip())\n",
    "            sentance_embedding, mask = self.get_sentence_embedding(processed_sentence)\n",
    "            paragraph_embedding[i] =  sentance_embedding\n",
    "            paragraph_mask[i] = mask\n",
    "            i+=1\n",
    "        return paragraph_embedding, paragraph_mask\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder():\n",
    "    def get_decoder_model():\n",
    "        return \"something\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en = encoder()\n",
    "# en.load_embedings()\n",
    "# y,  mask = en.get_paragraph_embedding(\"1 2 3 something's something!!. something else. other one this one\")\n",
    "# # print(y)\n",
    "# print(mask)\n",
    "# # x, mask = en.get_sentence_embedding(\"something something blabblublu\")\n",
    "# # print(len(x))\n",
    "# # print(x[2])\n",
    "# # print(mask)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_encoder:\n",
    "    def load_image(self,image_path,target_size):\n",
    "        img = skimage.io.imread(image_path)\n",
    "        image_resized = skimage.transform.resize(img, target_size, anti_aliasing=True)\n",
    "        return image_resized\n",
    "    \n",
    "    def extract_features(self,directory):\n",
    "        model = Xception()\n",
    "        model.layers.pop() \n",
    "        model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "#         print(model.summary())\n",
    "        features = dict()\n",
    "        i=0;\n",
    "        for name in os.listdir(directory):\n",
    "#             try:\n",
    "                filename = directory + '/' + name\n",
    "                image = self.load_image(filename, target_size=(299, 299))\n",
    "                if image.shape == (299, 299, 3):\n",
    "#                 print(image.shape)\n",
    "                    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "                    image = preprocess_input(image)\n",
    "                    feature = model.predict(image, verbose=0)\n",
    "                    image_id = name.split('.')[0]\n",
    "                    x = feature.ravel().tolist() \n",
    "                    features[name] = x\n",
    "                    print(i)\n",
    "                i +=1\n",
    "#             except:\n",
    "#                 continue \n",
    "        return features\n",
    "\n",
    "    def generate_image_vector(self,input_file, output_file):\n",
    "        x = self.extract_features(input_file)#\"/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/images/train/images/train\")  \n",
    "        j = json.dumps(x)\n",
    "        f = open(output_file, 'w')\n",
    "        print(j, file=f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie = image_encoder()\n",
    "# ie.generate_image_vector('/Users/vinutahegde/Documents/USC/SEM3/DL/project/ws/images/train/images/3', \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "404",
   "language": "python",
   "name": "404"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
